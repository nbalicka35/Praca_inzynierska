{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16329ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from app.utils.ResNet34Model import ResNet34Model\n",
    "from app.utils.HistogramEqualization import HistogramEqualization\n",
    "from app.utils.DatasetStatistics import DatasetStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    \"./config/resnet34.pth\", map_location=device, weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491acf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = checkpoint[\"image_size\"]\n",
    "MEAN = checkpoint[\"mean\"]\n",
    "STD = checkpoint[\"std\"]\n",
    "DIR = \"./new_data/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(DIR, transform=transforms)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b34175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34Model()\n",
    "model.load_state_dict(checkpoint[\"weights\"])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0dfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = next(iter(dl))\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = out.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "loss = out[:, class_index].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ec6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = model.get_activations_gradient()\n",
    "pool_gradients = torch.mean(grads, dim=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1436e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = model.get_activations().clone()\n",
    "\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pool_gradients[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "heatmap = F.relu(heatmap)  # reLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce771de",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap /= heatmap.max()  # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = heatmap.cpu().numpy()\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f543fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, _ = dataset.samples[0]\n",
    "img_original = cv2.imread(img_path)\n",
    "img_original = cv2.resize(img_original, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
    "heatmap = (heatmap * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe194313",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_img = cv2.addWeighted(img_original, 0.6, heatmap, 0.4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abefe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "axs[0].imshow(img_original)\n",
    "axs[0].set_title(f\"Original image ({dataset.classes[_]} class)\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB), cmap=\"jet\")\n",
    "axs[1].set_title(\"Grad-CAM\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "axs[2].imshow(superimposed_img, cmap=\"jet\")\n",
    "axs[2].set_title(\n",
    "    f\"Grad-CAM over the original image\\n(predicted {dataset.classes[class_index]} class)\"\n",
    ")\n",
    "axs[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_samples = {}\n",
    "for idx, (path, label) in enumerate(dataset.samples):\n",
    "    class_name = dataset.classes[label]\n",
    "    if class_name not in class_samples:\n",
    "        class_samples[class_name] = idx\n",
    "    if len(class_samples) == 4:\n",
    "        break\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "\n",
    "for row, (class_name, idx) in enumerate(class_samples.items()):\n",
    "    img_tensor = dataset[idx][0].unsqueeze(0).to(device)\n",
    "    img_path = dataset.samples[idx][0]\n",
    "\n",
    "    model.zero_grad()\n",
    "    out = model(img_tensor)\n",
    "    pred_idx = out.argmax(dim=1).item()\n",
    "    out[:, pred_idx].backward()\n",
    "\n",
    "    grads = model.get_activations_gradient()\n",
    "    acts = model.get_activations().clone()\n",
    "    weights = grads.mean(dim=(2, 3), keepdim=True)\n",
    "    cam = (weights * acts).sum(dim=1).squeeze()\n",
    "    cam = F.relu(cam)\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    cam = cam.cpu().detach().numpy()\n",
    "    cam = cv2.resize(cam, IMAGE_SIZE)\n",
    "\n",
    "    # Original\n",
    "    img_orig = cv2.imread(img_path)\n",
    "    img_orig = cv2.resize(img_orig, IMAGE_SIZE)\n",
    "    img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Heatmap\n",
    "    heatmap_colored = cv2.applyColorMap((cam * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Overlay\n",
    "    overlay = cv2.addWeighted(img_orig, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "    axes[row, 0].imshow(img_orig)\n",
    "    axes[row, 0].set_title(f\"True: {class_name}\")\n",
    "    axes[row, 0].axis(\"off\")\n",
    "\n",
    "    axes[row, 1].imshow(cam, cmap=\"jet\")\n",
    "    axes[row, 1].set_title(\"Grad-CAM\")\n",
    "    axes[row, 1].axis(\"off\")\n",
    "\n",
    "    axes[row, 2].imshow(overlay)\n",
    "    axes[row, 2].set_title(f\"Pred: {dataset.classes[pred_idx]}\")\n",
    "    axes[row, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
