{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn import metrics\n",
    "from app.utils.HistogramEqualization import HistogramEqualization\n",
    "from app.utils.ResNet34Model import ResNet34Model\n",
    "from app.utils.VGG16Model import VGG16Model\n",
    "from app.utils.EfficientNetModel import EfficientNetModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ImageDataLoader.ipynb\n",
    "%run ImageProcessor.ipynb\n",
    "%run DataExplorer.ipynb\n",
    "%run DatasetStatistics.ipynb\n",
    "%run DuplicateDetector.ipynb\n",
    "%run OversampledDataset.ipynb\n",
    "%run BatchVisualizer.ipynb\n",
    "%run Trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9791339",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./data/Training\"\n",
    "TEST_DIR = \"./data/Testing\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)\n",
    "VAL_SPLIT = 0.15\n",
    "\n",
    "EPOCHS = 5\n",
    "LEARNING_RATES = [0.01, 0.001, 0.0001, 0.00001]\n",
    "NUMBER_OF_CLASSES = 4\n",
    "\n",
    "FINAL_EPOCHS = 50\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc408f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (used)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch all GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # CUDA deterministic operations\n",
    "    torch.backends.cudnn.benchmark = False  # Turn off autotuning for reproducity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bcd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"Accelerator name: {torch.cuda.get_device_name(device)}\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daff1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageDataLoader(train_dir=TRAIN_DIR, test_dir=TEST_DIR)\n",
    "all_files = loader.load_all_images()\n",
    "\n",
    "print(f\"Successfully loaded {len(all_files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37056f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detector = DuplicateDetector(all_files)\n",
    "duplicate_detector.detect_duplicates()\n",
    "\n",
    "if len(duplicate_detector.duplicates) > 0:  # If duplicate files are present\n",
    "    duplicate_detector.remove_duplicates_from_disk()  # Removing duplicates entirely from disk\n",
    "    all_files = duplicate_detector.get_unique_files()  # Cleaning list with file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.print_dataset_class_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor(all_files)\n",
    "\n",
    "processor.load_grayscale_images(equalize=True)\n",
    "processor.display_image_grid(batch_size=32, figsize=(18, 9), images_per_row=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a55b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "explorator = DataExplorer(all_files)\n",
    "explorator.retrieve_sample_of_images(\n",
    "    [0, len(all_files) // 2, -1], equalize=True\n",
    ")  # First, middle and last image\n",
    "\n",
    "explorator.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94effa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = DatasetStatistics(processor.gray_images)\n",
    "\n",
    "stats.compute_stats()\n",
    "stats.print_stats()\n",
    "\n",
    "MEAN, STD = stats.get_normalized_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93840a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(12),\n",
    "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d03bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c997f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = datasets.ImageFolder(TRAIN_DIR)\n",
    "\n",
    "ind = list(range(len(base_dataset)))\n",
    "targets = [base_dataset.targets[i] for i in ind]\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    ind, test_size=VAL_SPLIT, random_state=42, stratify=targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_base = datasets.ImageFolder(TRAIN_DIR, transform=test_transform)\n",
    "valset = Subset(val_base, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = OversampledDataset(TRAIN_DIR, transform=train_transform, indices=train_idx)\n",
    "testset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "print()\n",
    "trainset.print_class_distribution()\n",
    "\n",
    "print()\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Validation samples: {len(valset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Classes: {trainset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18effde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(trainset, BATCH_SIZE, shuffle=True, num_workers=0, generator=g)\n",
    "val_dl = DataLoader(valset, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dl = DataLoader(testset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = BatchVisualizer(trainset.classes, mean=[MEAN] * 3, std=[STD] * 3)\n",
    "\n",
    "visualizer.visualize_batch(train_dl)\n",
    "visualizer.visualize_classes(val_dl, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"VGG-16\": VGG16Model,\n",
    "    \"ResNet34\": ResNet34Model,\n",
    "    \"EfficientNet_B0\": EfficientNetModel,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_config = {\n",
    "    \"sgd\": lambda params, lr: optim.SGD(params, lr=lr),\n",
    "    \"sgd_momentum\": lambda params, lr: optim.SGD(params, lr=lr, momentum=0.9),\n",
    "    \"adam\": lambda params, lr: optim.Adam(params, lr=lr),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model_class, optimizer_fn, lr, train_dl, val_dl, device, epochs=EPOCHS\n",
    "):\n",
    "    set_seed(42)\n",
    "\n",
    "    model = model_class(NUMBER_OF_CLASSES)\n",
    "    trainer = Trainer(model, device)\n",
    "    optimizer = optimizer_fn(model.parameters(), lr)\n",
    "\n",
    "    history = trainer.fit(train_dl, val_dl, optimizer, epochs)\n",
    "\n",
    "    return {\n",
    "        \"last_epoch_val_acc\": history[\"val_acc\"][-1],\n",
    "        \"best_val_acc\": max(history[\"val_acc\"]),\n",
    "        \"last_epoch_val_loss\": history[\"val_loss\"][-1],\n",
    "        \"history\": history,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments(train_dl, val_dl, device):\n",
    "    res = []\n",
    "\n",
    "    total = len(models_config) * len(optimizers_config) * len(LEARNING_RATES)\n",
    "    current = 0\n",
    "\n",
    "    for model_name, model_class in models_config.items():\n",
    "        for optim_name, optim_fn in optimizers_config.items():\n",
    "            for lr in LEARNING_RATES:\n",
    "                current += 1\n",
    "                print(f\"\\n[{current}/{total}] {model_name} + {optim_name} + lr={lr}\")\n",
    "\n",
    "                result = run_experiment(\n",
    "                    model_class, optim_fn, lr, train_dl, val_dl, device\n",
    "                )\n",
    "\n",
    "                res.append(\n",
    "                    {\n",
    "                        \"model\": model_name,\n",
    "                        \"optimizer\": optim_name,\n",
    "                        \"learning rate\": lr,\n",
    "                        **result,\n",
    "                    }\n",
    "                )\n",
    "                print(\n",
    "                    f\"Last epoch's validation accuracy: {result['last_epoch_val_acc']:.4f}\"\n",
    "                )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all_experiments(train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef702b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "vgg16_model = VGG16Model()\n",
    "optimizer_vgg16 = optim.Adam(vgg16_model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer_vgg16 = Trainer(vgg16_model, device)\n",
    "vgg16_history = trainer_vgg16.fit(\n",
    "    train_dl, val_dl, optimizer_vgg16, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "vgg16_acc, vgg16_preds, vgg16_labels = trainer_vgg16.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" VGG-16 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        vgg16_labels, vgg16_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e40ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "resnet34_model = ResNet34Model()\n",
    "optimizer_resnet = optim.SGD(resnet34_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer_resnet34 = Trainer(resnet34_model, device)\n",
    "resnet34_history = trainer_resnet34.fit(\n",
    "    train_dl, val_dl, optimizer_resnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "resnet34_acc, resnet34_preds, resnet34_labels = trainer_resnet34.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5680e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" RESNET34 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        resnet34_labels, resnet34_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d835164",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "efficientnet_model = EfficientNetModel()\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "\n",
    "trainer_efficientnet = Trainer(efficientnet_model, device)\n",
    "efficientnet_history = trainer_efficientnet.fit(\n",
    "    train_dl, val_dl, optimizer_efficientnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "efficientnet_acc, efficientnet_preds, efficientnet_labels = trainer_efficientnet.test(\n",
    "    test_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" EFFICIENTNET CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        efficientnet_labels, efficientnet_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_accuracy(train_acc, val_acc, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_acc, \"r--\", label=\"Training accuracy\")\n",
    "    ax.plot(val_acc, \"b-\", label=\"Validation accuracy\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_train_val_loss(train_loss, val_loss, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_loss, \"g--\", label=\"Training loss\")\n",
    "    ax.plot(val_loss, \"m-\", label=\"Validation loss\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_accuracy(\n",
    "    vgg16_history[\"train_acc\"], vgg16_history[\"val_acc\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    resnet34_history[\"train_acc\"], resnet34_history[\"val_acc\"], \"ResNet34 model\", axs[1]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    efficientnet_history[\"train_acc\"],\n",
    "    efficientnet_history[\"val_acc\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training accuracy vs validation accuracy\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db32782",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_loss(\n",
    "    vgg16_history[\"train_loss\"], vgg16_history[\"val_loss\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    resnet34_history[\"train_loss\"],\n",
    "    resnet34_history[\"val_loss\"],\n",
    "    \"ResNet34 model\",\n",
    "    axs[1],\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    efficientnet_history[\"train_loss\"],\n",
    "    efficientnet_history[\"val_loss\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training loss vs validation loss\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    [vgg16_labels, vgg16_preds],\n",
    "    [resnet34_labels, resnet34_preds],\n",
    "    [efficientnet_labels, efficientnet_preds],\n",
    "]\n",
    "\n",
    "_, axs = plt.subplots(ncols=3, figsize=(28, 8))\n",
    "i = 0\n",
    "\n",
    "for model in models_config:\n",
    "    cm = metrics.confusion_matrix(results[i][0], results[i][1])\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=testset.class_to_idx)\n",
    "    cm_display.plot(cmap=\"Blues\", ax=axs[i], text_kw={\"fontsize\": 14})\n",
    "\n",
    "    axs[i].set_title(f\"{model} confusion matrix\", y=1.02, fontsize=18)\n",
    "\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45, labelsize=12)\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), ha=\"right\")\n",
    "\n",
    "    axs[i].tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "    axs[i].set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.suptitle(\"Confusion matrix for all models\", fontsize=\"22\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428980",
   "metadata": {},
   "outputs": [],
   "source": [
    "glioma_test_paths = []\n",
    "count = 0\n",
    "samples = 10\n",
    "\n",
    "for path, label in testset.samples:\n",
    "    if label == 0 and count < samples:\n",
    "        count += 1\n",
    "        glioma_test_paths.append(path)\n",
    "\n",
    "glioma_train_paths = []\n",
    "count = 0\n",
    "\n",
    "for path, label in trainset.samples:\n",
    "    if label == 0 and count < samples:\n",
    "        count += 1\n",
    "        glioma_train_paths.append(path)\n",
    "\n",
    "meningioma_test_paths = []\n",
    "count = 0\n",
    "\n",
    "for path, label in testset.samples:\n",
    "    if label == 1 and count < samples:\n",
    "        count += 1\n",
    "        meningioma_test_paths.append(path)\n",
    "\n",
    "_, axs = plt.subplots(1, samples, figsize=(samples * 3, 3))\n",
    "\n",
    "for i, path in enumerate(glioma_train_paths):\n",
    "    img = plt.imread(path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Glioma train - {samples} samples of images\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "_, axs = plt.subplots(1, samples, figsize=(samples * 3, 3))\n",
    "\n",
    "for i, path in enumerate(glioma_test_paths):\n",
    "    img = plt.imread(path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Glioma test - {samples} samples of images\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "_, axs = plt.subplots(1, samples, figsize=(samples * 3, 3))\n",
    "\n",
    "for i, path in enumerate(meningioma_test_paths):\n",
    "    img = plt.imread(path)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Meningioma test - {samples} samples of images\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
