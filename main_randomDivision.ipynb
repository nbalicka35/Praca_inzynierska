{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88baa87a",
   "metadata": {},
   "source": [
    "Import libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5bc92",
   "metadata": {},
   "source": [
    "Import classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b20db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.HistogramEqualization import HistogramEqualization\n",
    "from app.utils.ResNet34Model import ResNet34Model\n",
    "from app.utils.VGG16Model import VGG16Model\n",
    "from app.utils.EfficientNetModel import EfficientNetModel\n",
    "from app.utils.ImageDataLoader import ImageDataLoader\n",
    "from app.utils.ImageProcessor import ImageProcessor\n",
    "from app.utils.DataExplorer import DataExplorer\n",
    "from app.utils.DatasetStatistics import DatasetStatistics\n",
    "from app.utils.DuplicateDetector import DuplicateDetector\n",
    "from app.utils.OversampledDataset import OversampledDataset\n",
    "from app.utils.BatchVisualizer import BatchVisualizer\n",
    "from app.utils.Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e160c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DatasetDivider.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc99b6",
   "metadata": {},
   "source": [
    "Prepare constant variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./new_data/Training\"\n",
    "VAL_DIR = \"./new_data/Validation\"\n",
    "TEST_DIR = \"./new_data/Testing\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUMBER_OF_CLASSES = 4\n",
    "\n",
    "FINAL_EPOCHS = 50\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824f62b",
   "metadata": {},
   "source": [
    "Definition of function setting same seed to maintain reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d86215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (used)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch all GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # CUDA deterministic operations\n",
    "    torch.backends.cudnn.benchmark = False  # Turn off autotuning for reproducity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af99a7",
   "metadata": {},
   "source": [
    "Check if accelerator is available. If not, use cpu instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89232bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"Accelerator name: {torch.cuda.get_device_name(device)}\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ebd995",
   "metadata": {},
   "source": [
    "**Run following cell only if new dataset division is necessary**.<br>\n",
    "Otherwise, skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = DatasetDivider()\n",
    "split_data = divider.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e87d10",
   "metadata": {},
   "source": [
    "Load images from specified train, validation and test directories. Validation directory is optional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb35908",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageDataLoader(TRAIN_DIR, VAL_DIR, TEST_DIR)\n",
    "all_files = loader.load_all_images()\n",
    "\n",
    "print(f\"Successfully loaded {len(all_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02699c7b",
   "metadata": {},
   "source": [
    "Check loaded data for any instances of duplicate. Check class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detector = DuplicateDetector(all_files)\n",
    "duplicate_detector.detect_duplicates()\n",
    "\n",
    "if len(duplicate_detector.duplicates) > 0:  # If duplicate files are present\n",
    "    duplicate_detector.remove_duplicates_from_disk()  # Removing duplicates entirely from disk\n",
    "    all_files = duplicate_detector.get_unique_files()  # Cleaning list with file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27484014",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.print_dataset_class_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c3821",
   "metadata": {},
   "source": [
    "Convert loaded images to grayscale, apply histogram equalization.<br>\n",
    "Display batch of 32 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor(all_files)\n",
    "\n",
    "processor.load_grayscale_images(equalize=True)\n",
    "processor.display_image_grid(batch_size=32, figsize=(18, 9), images_per_row=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed1959",
   "metadata": {},
   "source": [
    "Get 1st, middle and last images' histograms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explorator = DataExplorer(all_files)\n",
    "explorator.retrieve_sample_of_images(\n",
    "    [0, len(all_files) // 2, -1], equalize=True\n",
    ")  # First, middle and last image\n",
    "\n",
    "explorator.plot_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c17d79",
   "metadata": {},
   "source": [
    "Compute mean and standard deviation values based on provided dataset. Default values for ImageNet set are inappropriate due to gray-scale MRI format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = DatasetStatistics(processor.gray_images)\n",
    "\n",
    "stats.compute_stats()\n",
    "stats.print_stats()\n",
    "\n",
    "MEAN, STD = stats.get_normalized_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7014987",
   "metadata": {},
   "source": [
    "Prepare transformations, including data augmentation for training set. `test_transform` will be applied to validation set as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae00b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(12),\n",
    "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44832948",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3a5b0",
   "metadata": {},
   "source": [
    "Use generic data loader and apply transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e502468",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = OversampledDataset(TRAIN_DIR, transform=train_transform)\n",
    "valset = datasets.ImageFolder(VAL_DIR, transform=test_transform)\n",
    "testset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "print()\n",
    "trainset.print_class_distribution()\n",
    "\n",
    "print()\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Validation samples: {len(valset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Classes: {trainset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc45c2",
   "metadata": {},
   "source": [
    "Seed the generator passed to `DataLoader` for reproducibility. Shuffle tran samples to avoid samples being remembered instead of generalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dl = DataLoader(trainset, BATCH_SIZE, shuffle=True, num_workers=0, generator=g)\n",
    "val_dl = DataLoader(valset, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dl = DataLoader(testset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e588124",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = BatchVisualizer(trainset.classes, mean=[MEAN] * 3, std=[STD] * 3)\n",
    "\n",
    "visualizer.visualize_batch(train_dl)\n",
    "visualizer.visualize_classes(test_dl, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8dc77b",
   "metadata": {},
   "source": [
    "Configure models, optimizers and learning rates to later on run experiments and choose the best combinations of these parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"VGG-16\": VGG16Model,\n",
    "    \"ResNet34\": ResNet34Model,\n",
    "    \"EfficientNet_B0\": EfficientNetModel,\n",
    "}\n",
    "\n",
    "optimizers_config = {\n",
    "    \"sgd\": lambda params, lr: optim.SGD(params, lr=lr),\n",
    "    \"sgd_momentum\": lambda params, lr: optim.SGD(params, lr=lr, momentum=0.9),\n",
    "    \"adam\": lambda params, lr: optim.Adam(params, lr=lr),\n",
    "}\n",
    "\n",
    "LEARNING_RATES = [0.01, 0.001, 0.0001, 0.00001]\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa11c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model_class, optimizer_fn, lr, train_dl, val_dl, device, epochs=EPOCHS\n",
    "):\n",
    "    set_seed(42)\n",
    "\n",
    "    model = model_class(NUMBER_OF_CLASSES)\n",
    "    trainer = Trainer(model, device)\n",
    "    optimizer = optimizer_fn(model.parameters(), lr)\n",
    "\n",
    "    history = trainer.fit(train_dl, val_dl, optimizer, epochs)\n",
    "\n",
    "    return {\n",
    "        \"last_epoch_val_acc\": history[\"val_acc\"][-1],\n",
    "        \"best_val_acc\": max(history[\"val_acc\"]),\n",
    "        \"last_epoch_val_loss\": history[\"val_loss\"][-1],\n",
    "        \"history\": history,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_all_experiments(train_dl, val_dl, device):\n",
    "    res = []\n",
    "\n",
    "    total = len(models_config) * len(optimizers_config) * len(LEARNING_RATES)\n",
    "    current = 0\n",
    "\n",
    "    for model_name, model_class in models_config.items():\n",
    "        for optim_name, optim_fn in optimizers_config.items():\n",
    "            for lr in LEARNING_RATES:\n",
    "                current += 1\n",
    "                print(f\"\\n[{current}/{total}] {model_name} + {optim_name} + lr={lr}\")\n",
    "\n",
    "                result = run_experiment(\n",
    "                    model_class, optim_fn, lr, train_dl, val_dl, device\n",
    "                )\n",
    "\n",
    "                res.append(\n",
    "                    {\n",
    "                        \"model\": model_name,\n",
    "                        \"optimizer\": optim_name,\n",
    "                        \"learning rate\": lr,\n",
    "                        **result,\n",
    "                    }\n",
    "                )\n",
    "                print(\n",
    "                    f\"Last epoch's validation accuracy: {result['last_epoch_val_acc']:.4f}\"\n",
    "                )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ec2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all_experiments(train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13678f8d",
   "metadata": {},
   "source": [
    "Amongst VGG-16 model combinations, Adam optimizer + lr=0.0001 turned out to be the best in regard of accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46aeead",
   "metadata": {},
   "source": [
    "Train and test the model, measure its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "vgg16_model = VGG16Model(NUMBER_OF_CLASSES)\n",
    "optimizer_vgg16 = optim.Adam(vgg16_model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer_vgg16 = Trainer(vgg16_model, device)\n",
    "vgg16_history = trainer_vgg16.fit(\n",
    "    train_dl, val_dl, optimizer_vgg16, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "vgg16_acc, vgg16_preds, vgg16_labels = trainer_vgg16.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d22ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" VGG-16 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        vgg16_labels, vgg16_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3396d4",
   "metadata": {},
   "source": [
    "Amongst ResNet-34 model combinations, stochastic gradient descent optimizer + lr=0.001 turned out to be the best in regard of accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c4cda",
   "metadata": {},
   "source": [
    "Train and test the model, measure its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "resnet34_model = ResNet34Model()\n",
    "optimizer_resnet = optim.SGD(resnet34_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer_resnet34 = Trainer(resnet34_model, device)\n",
    "resnet34_history = trainer_resnet34.fit(\n",
    "    train_dl, val_dl, optimizer_resnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "resnet34_acc, resnet34_preds, resnet34_labels = trainer_resnet34.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ac457",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" RESNET34 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        resnet34_labels, resnet34_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f539b4",
   "metadata": {},
   "source": [
    "Amongst EfficientNet B0 weights model combinations, Adam optimizer + lr=0.001 turned out to be the best in regard of accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e1241",
   "metadata": {},
   "source": [
    "Train and test the model, measure its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "efficientnet_model = EfficientNetModel()\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "\n",
    "trainer_efficientnet = Trainer(efficientnet_model, device)\n",
    "efficientnet_history = trainer_efficientnet.fit(\n",
    "    train_dl, val_dl, optimizer_efficientnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "efficientnet_acc, efficientnet_preds, efficientnet_labels = trainer_efficientnet.test(\n",
    "    test_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43438422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" EFFICIENTNET CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        efficientnet_labels, efficientnet_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ef2b0",
   "metadata": {},
   "source": [
    "Plotting training & validation set accuracy and loss functions definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838aa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_accuracy(train_acc, val_acc, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_acc, \"r--\", label=\"Training accuracy\")\n",
    "    ax.plot(val_acc, \"b-\", label=\"Validation accuracy\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_train_val_loss(train_loss, val_loss, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_loss, \"g--\", label=\"Training loss\")\n",
    "    ax.plot(val_loss, \"m-\", label=\"Validation loss\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284cc4e",
   "metadata": {},
   "source": [
    "Plot VGG-16, ResNet-34 and EfficientNet train & validation set accuracy against each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fefeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_accuracy(\n",
    "    vgg16_history[\"train_acc\"], vgg16_history[\"val_acc\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    resnet34_history[\"train_acc\"], resnet34_history[\"val_acc\"], \"ResNet34 model\", axs[1]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    efficientnet_history[\"train_acc\"],\n",
    "    efficientnet_history[\"val_acc\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training accuracy vs validation accuracy\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc7ec5",
   "metadata": {},
   "source": [
    "Plot VGG-16, ResNet-34 and EfficientNet train & validation set loss against each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8960de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_loss(\n",
    "    vgg16_history[\"train_loss\"], vgg16_history[\"val_loss\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    resnet34_history[\"train_loss\"],\n",
    "    resnet34_history[\"val_loss\"],\n",
    "    \"ResNet34 model\",\n",
    "    axs[1],\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    efficientnet_history[\"train_loss\"],\n",
    "    efficientnet_history[\"val_loss\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training loss vs validation loss\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71f5f2",
   "metadata": {},
   "source": [
    "Aggregate the results to compare models. Plot confusion matrix for each one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    [vgg16_labels, vgg16_preds],\n",
    "    [resnet34_labels, resnet34_preds],\n",
    "    [efficientnet_labels, efficientnet_preds],\n",
    "]\n",
    "\n",
    "_, axs = plt.subplots(ncols=3, figsize=(28, 8))\n",
    "i = 0\n",
    "\n",
    "for model in models_config:\n",
    "    cm = metrics.confusion_matrix(results[i][0], results[i][1])\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=testset.class_to_idx)\n",
    "    cm_display.plot(cmap=\"Blues\", ax=axs[i], text_kw={\"fontsize\": 14})\n",
    "\n",
    "    axs[i].set_title(f\"{model} confusion matrix\", y=1.02, fontsize=18)\n",
    "\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45, labelsize=12)\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), ha=\"right\")\n",
    "\n",
    "    axs[i].tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "    axs[i].set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.suptitle(\"Confusion matrix for each model\", fontsize=\"22\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a94172",
   "metadata": {},
   "source": [
    "Additional experiments showed ResNet's model superiority over VGG-16 and EfficienNet models. Final setting:<br>\n",
    "**ResNet34 + sgd_momentum=0.9 + lr=0.001, collorJitter settings at .15 and histogram equalization**<br><br>\n",
    "Export the model to .pth file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5127de",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"weights\": trainer_resnet34.model.state_dict(),\n",
    "    \"mean\": MEAN,\n",
    "    \"std\": STD,\n",
    "    \"image_size\": IMAGE_SIZE,\n",
    "    \"hist_eq\": True,\n",
    "}\n",
    "# torch.save(checkpoint, \"./config/resnet34.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
