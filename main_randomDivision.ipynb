{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e160c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ImageDataLoader.ipynb\n",
    "%run ImageProcessor.ipynb\n",
    "%run DataExplorer.ipynb\n",
    "%run DatasetStatistics.ipynb\n",
    "%run DuplicateDetector.ipynb\n",
    "%run OversampledDataset.ipynb\n",
    "%run BatchVisualizer.ipynb\n",
    "%run VGG16Model.ipynb\n",
    "%run ResNet34Model.ipynb\n",
    "%run EfficientNetModel.ipynb\n",
    "%run Trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./new_data/Training\"\n",
    "VAL_DIR = \"./new_data/Validation\"\n",
    "TEST_DIR = \"./new_data/Testing\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUMBER_OF_CLASSES = 4\n",
    "\n",
    "FINAL_EPOCHS = 50\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89232bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"Accelerator name: {torch.cuda.get_device_name(device)}\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d86215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (used)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch all GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # CUDA deterministic operations\n",
    "    torch.backends.cudnn.benchmark = False  # Turn off autotuning for reproducity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DatasetDivider.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = DatasetDivider()\n",
    "split_data = divider.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb35908",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageDataLoader(TRAIN_DIR, VAL_DIR, TEST_DIR)\n",
    "all_files = loader.load_all_images()\n",
    "\n",
    "print(f\"Successfully loaded {len(all_files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detector = DuplicateDetector(all_files)\n",
    "duplicate_detector.detect_duplicates()\n",
    "\n",
    "if len(duplicate_detector.duplicates) > 0:  # If duplicate files are present\n",
    "    duplicate_detector.remove_duplicates_from_disk()  # Removing duplicates entirely from disk\n",
    "    all_files = duplicate_detector.get_unique_files()  # Cleaning list with file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27484014",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.print_dataset_class_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor(all_files)\n",
    "\n",
    "processor.load_grayscale_images()\n",
    "processor.display_image_grid(batch_size=32, figsize=(18, 9), images_per_row=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explorator = DataExplorer(all_files)\n",
    "explorator.retrieve_sample_of_images(\n",
    "    [0, len(all_files) // 2, -1],  # equalize=True\n",
    ")  # First, middle and last image\n",
    "\n",
    "explorator.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = DatasetStatistics(processor.gray_images)\n",
    "\n",
    "stats.compute_stats()\n",
    "stats.print_stats()\n",
    "\n",
    "MEAN, STD = stats.get_normalized_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "class HistogramEqualization:\n",
    "    def __call__(self, img):\n",
    "        return ImageOps.equalize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae00b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(12),\n",
    "        transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44832948",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        HistogramEqualization(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e502468",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = OversampledDataset(TRAIN_DIR, transform=train_transform)\n",
    "valset = datasets.ImageFolder(VAL_DIR, transform=test_transform)\n",
    "testset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "print()\n",
    "trainset.print_class_distribution()\n",
    "\n",
    "print()\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Validation samples: {len(valset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Classes: {trainset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dl = DataLoader(trainset, BATCH_SIZE, shuffle=True, num_workers=0, generator=g)\n",
    "val_dl = DataLoader(valset, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dl = DataLoader(testset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"VGG-16\": VGG16Model,\n",
    "    \"ResNet34\": ResNet34Model,\n",
    "    \"EfficientNet_B0\": EfficientNetModel,\n",
    "}\n",
    "\n",
    "optimizers_config = {\n",
    "    \"sgd\": lambda params, lr: optim.SGD(params, lr=lr),\n",
    "    \"sgd_momentum\": lambda params, lr: optim.SGD(params, lr=lr, momentum=0.9),\n",
    "    \"adam\": lambda params, lr: optim.Adam(params, lr=lr),\n",
    "}\n",
    "\n",
    "LEARNING_RATES = [0.01, 0.001, 0.0001, 0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa11c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model_class, optimizer_fn, lr, train_dl, val_dl, device, epochs=EPOCHS\n",
    "):\n",
    "    set_seed(42)\n",
    "\n",
    "    model = model_class(NUMBER_OF_CLASSES)\n",
    "    trainer = Trainer(model, device)\n",
    "    optimizer = optimizer_fn(model.parameters(), lr)\n",
    "\n",
    "    history = trainer.fit(train_dl, val_dl, optimizer, epochs)\n",
    "\n",
    "    return {\n",
    "        \"last_epoch_val_acc\": history[\"val_acc\"][-1],\n",
    "        \"best_val_acc\": max(history[\"val_acc\"]),\n",
    "        \"last_epoch_val_loss\": history[\"val_loss\"][-1],\n",
    "        \"history\": history,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_all_experiments(train_dl, val_dl, device):\n",
    "    res = []\n",
    "\n",
    "    total = len(models_config) * len(optimizers_config) * len(LEARNING_RATES)\n",
    "    current = 0\n",
    "\n",
    "    for model_name, model_class in models_config.items():\n",
    "        for optim_name, optim_fn in optimizers_config.items():\n",
    "            for lr in LEARNING_RATES:\n",
    "                current += 1\n",
    "                print(f\"\\n[{current}/{total}] {model_name} + {optim_name} + lr={lr}\")\n",
    "\n",
    "                result = run_experiment(\n",
    "                    model_class, optim_fn, lr, train_dl, val_dl, device\n",
    "                )\n",
    "\n",
    "                res.append(\n",
    "                    {\n",
    "                        \"model\": model_name,\n",
    "                        \"optimizer\": optim_name,\n",
    "                        \"learning rate\": lr,\n",
    "                        **result,\n",
    "                    }\n",
    "                )\n",
    "                print(\n",
    "                    f\"Last epoch's validation accuracy: {result['last_epoch_val_acc']:.4f}\"\n",
    "                )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ec2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all_experiments(train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16Model(NUMBER_OF_CLASSES)\n",
    "optimizer_vgg16 = optim.Adam(vgg16_model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer_vgg16 = Trainer(vgg16_model, device)\n",
    "vgg16_history = trainer_vgg16.fit(\n",
    "    train_dl, val_dl, optimizer_vgg16, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "vgg16_acc, vgg16_preds, vgg16_labels = trainer_vgg16.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d22ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" VGG-16 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        vgg16_labels, vgg16_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "resnet34_model = ResNet34Model()\n",
    "optimizer_resnet = optim.SGD(resnet34_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer_resnet34 = Trainer(resnet34_model, device)\n",
    "resnet34_history = trainer_resnet34.fit(\n",
    "    train_dl, val_dl, optimizer_resnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "resnet34_acc, resnet34_preds, resnet34_labels = trainer_resnet34.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ac457",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" RESNET34 CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        resnet34_labels, resnet34_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "efficientnet_model = EfficientNetModel()\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "\n",
    "trainer_efficientnet = Trainer(efficientnet_model, device)\n",
    "efficientnet_history = trainer_efficientnet.fit(\n",
    "    train_dl, val_dl, optimizer_efficientnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "efficientnet_acc, efficientnet_preds, efficientnet_labels = trainer_efficientnet.test(\n",
    "    test_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43438422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\" * 20 + \" EFFICIENTNET CLASSIFICATION STATISTICS \" + \"#\" * 20)\n",
    "print()\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        efficientnet_labels, efficientnet_preds, target_names=testset.classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838aa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_accuracy(train_acc, val_acc, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_acc, \"r--\", label=\"Training accuracy\")\n",
    "    ax.plot(val_acc, \"b-\", label=\"Validation accuracy\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a05166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss(train_loss, val_loss, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_loss, \"g--\", label=\"Training loss\")\n",
    "    ax.plot(val_loss, \"m-\", label=\"Validation loss\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fefeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_accuracy(\n",
    "    vgg16_history[\"train_acc\"], vgg16_history[\"val_acc\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    resnet34_history[\"train_acc\"], resnet34_history[\"val_acc\"], \"ResNet34 model\", axs[1]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    efficientnet_history[\"train_acc\"],\n",
    "    efficientnet_history[\"val_acc\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training accuracy vs validation accuracy\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8960de",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_loss(\n",
    "    vgg16_history[\"train_loss\"], vgg16_history[\"val_loss\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    resnet34_history[\"train_loss\"],\n",
    "    resnet34_history[\"val_loss\"],\n",
    "    \"ResNet34 model\",\n",
    "    axs[1],\n",
    ")\n",
    "\n",
    "plot_train_val_loss(\n",
    "    efficientnet_history[\"train_loss\"],\n",
    "    efficientnet_history[\"val_loss\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training loss vs validation loss\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    [vgg16_labels, vgg16_preds],\n",
    "    [resnet34_labels, resnet34_preds],\n",
    "    [efficientnet_labels, efficientnet_preds],\n",
    "]\n",
    "\n",
    "_, axs = plt.subplots(ncols=3, figsize=(28, 8))\n",
    "i = 0\n",
    "\n",
    "for model in models_config:\n",
    "    cm = metrics.confusion_matrix(results[i][0], results[i][1])\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=testset.class_to_idx)\n",
    "    cm_display.plot(cmap=\"Blues\", ax=axs[i], text_kw={\"fontsize\": 14})\n",
    "\n",
    "    axs[i].set_title(f\"{model} confusion matrix\", y=1.02, fontsize=18)\n",
    "\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45, labelsize=12)\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), ha=\"right\")\n",
    "\n",
    "    axs[i].tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "    axs[i].set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.suptitle(\"Confusion matrix for all models\", fontsize=\"22\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean the main files' content, consider other way to oversample classes (no tumor has nearly Â¬500 samples, where rest of the classes are >= 600), \\\n",
    "#  make sure noRandomDivision will work in the current architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOSEN MODEL: ResNet34 + sgd_momentum + lr=0.001 WITH collorJitter settings at .15 and with histogram equalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
