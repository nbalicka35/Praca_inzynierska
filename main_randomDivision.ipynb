{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e160c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ImageDataLoader.ipynb\n",
    "%run ImageProcessor.ipynb\n",
    "%run DataExplorer.ipynb\n",
    "%run DatasetStatistics.ipynb\n",
    "%run DuplicateDetector.ipynb\n",
    "%run OversampledDataset.ipynb\n",
    "%run BatchVisualizer.ipynb\n",
    "%run VGG16Model.ipynb\n",
    "%run ResNet34Model.ipynb\n",
    "%run EfficientNetModel.ipynb\n",
    "%run Trainer.ipynb\n",
    "%run DatasetDivider.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./new_data/Training\"\n",
    "VAL_DIR = \"./new_data/Validation\"\n",
    "TEST_DIR = \"./new_data/Testing\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUMBER_OF_CLASSES = 4\n",
    "\n",
    "FINAL_EPOCHS = 50\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89232bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"Accelerator name: {torch.cuda.get_device_name(device)}\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d86215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (used)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch all GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # CUDA deterministic operations\n",
    "    torch.backends.cudnn.benchmark = False  # Turn off autotuning for reproducity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = collect_all_images()\n",
    "\n",
    "create_directory_structure()\n",
    "split_data = split_and_copy(all_samples)\n",
    "\n",
    "print_statistics(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb35908",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageDataLoader(TRAIN_DIR, VAL_DIR, TEST_DIR)\n",
    "all_files = loader.load_all_images()\n",
    "\n",
    "print(f\"Successfully loaded {len(all_files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policz pliki w oryginalnych folderach\n",
    "original_train = sum(len(files) for _, _, files in os.walk(\"./data/Training\"))\n",
    "original_test = sum(len(files) for _, _, files in os.walk(\"./data/Testing\"))\n",
    "print(\n",
    "    f\"Oryginalne: Training={original_train}, Testing={original_test}, Suma={original_train + original_test}\"\n",
    ")\n",
    "\n",
    "# Policz pliki w nowych folderach\n",
    "new_total = sum(len(files) for _, _, files in os.walk(\"./new_data\"))\n",
    "print(f\"Nowe (new_data): {new_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detector = DuplicateDetector(all_files)\n",
    "duplicate_detector.detect_duplicates()\n",
    "\n",
    "if len(duplicate_detector.duplicates) > 0:  # If duplicate files are present\n",
    "    duplicate_detector.remove_duplicates_from_disk()  # Removing duplicates entirely from disk\n",
    "    all_files = duplicate_detector.get_unique_files()  # Cleaning list with file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27484014",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.print_dataset_class_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor(all_files)\n",
    "\n",
    "processor.load_grayscale_images()\n",
    "processor.display_image_grid(batch_size=32, figsize=(18, 9), images_per_row=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explorator = DataExplorer(all_files)\n",
    "explorator.retrieve_sample_of_images(\n",
    "    [0, len(all_files) // 2, -1],  # equalize=True\n",
    ")  # First, middle and last image\n",
    "\n",
    "explorator.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = DatasetStatistics(processor.gray_images)\n",
    "\n",
    "stats.compute_stats()\n",
    "stats.print_stats()\n",
    "\n",
    "MEAN, STD = stats.get_normalized_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae00b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        # HistogramEqualization(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(12),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.15, contrast=0.15\n",
    "        ),  # consider changing to 0.3 to elevate test acc results\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44832948",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        # HistogramEqualization(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[MEAN] * 3, std=[STD] * 3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e502468",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = OversampledDataset(TRAIN_DIR, transform=train_transform)\n",
    "valset = datasets.ImageFolder(VAL_DIR, transform=test_transform)\n",
    "testset = datasets.ImageFolder(TEST_DIR, transform=test_transform)\n",
    "\n",
    "print()\n",
    "trainset.print_class_distribution()\n",
    "\n",
    "print()\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Validation samples: {len(valset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Classes: {trainset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dl = DataLoader(trainset, BATCH_SIZE, shuffle=True, num_workers=0, generator=g)\n",
    "val_dl = DataLoader(valset, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dl = DataLoader(testset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16Model(NUMBER_OF_CLASSES)\n",
    "optimizer_vgg16 = optim.Adam(vgg16_model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer_vgg16 = Trainer(vgg16_model, device)\n",
    "vgg16_history = trainer_vgg16.fit(\n",
    "    train_dl, val_dl, optimizer_vgg16, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "vgg16_acc, vgg16_preds, vgg16_labels = trainer_vgg16.test(test_dl)\n",
    "print(f\"\\nVGG-16 Test accuracy: {vgg16_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "resnet34_model = ResNet34Model()\n",
    "optimizer_resnet = optim.SGD(resnet34_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer_resnet34 = Trainer(resnet34_model, device)\n",
    "resnet34_history = trainer_resnet34.fit(\n",
    "    train_dl, val_dl, optimizer_resnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "resnet34_acc, resnet34_preds, resnet34_labels = trainer_resnet34.test(test_dl)\n",
    "print(f\"Test accuracy: {resnet34_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "efficientnet_model = EfficientNetModel()\n",
    "optimizer_efficientnet = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "\n",
    "trainer_efficientnet = Trainer(efficientnet_model, device)\n",
    "efficientnet_history = trainer_efficientnet.fit(\n",
    "    train_dl, val_dl, optimizer_efficientnet, FINAL_EPOCHS, PATIENCE\n",
    ")\n",
    "efficientnet_acc, efficientnet_preds, efficientnet_labels = trainer_efficientnet.test(\n",
    "    test_dl\n",
    ")\n",
    "print(f\"Test accuracy: {efficientnet_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838aa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_accuracy(train_acc, val_acc, title=None, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train_acc, \"r--\", label=\"Training accuracy\")\n",
    "    ax.plot(val_acc, \"b-\", label=\"Validation accuracy\")\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=10)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fefeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "plot_train_val_accuracy(\n",
    "    vgg16_history[\"train_acc\"], vgg16_history[\"val_acc\"], \"VGG-16 model\", axs[0]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    resnet34_history[\"train_acc\"], resnet34_history[\"val_acc\"], \"ResNet34 model\", axs[1]\n",
    ")\n",
    "\n",
    "plot_train_val_accuracy(\n",
    "    efficientnet_history[\"train_acc\"],\n",
    "    efficientnet_history[\"val_acc\"],\n",
    "    \"EfficientNet model\",\n",
    "    axs[2],\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Models training accuracy vs validation accuracy\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"VGG-16\": VGG16Model,\n",
    "    \"ResNet34\": ResNet34Model,\n",
    "    \"EfficientNet_B0\": EfficientNetModel,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    [vgg16_labels, vgg16_preds],\n",
    "    [resnet34_labels, resnet34_preds],\n",
    "    [efficientnet_labels, efficientnet_preds],\n",
    "]\n",
    "\n",
    "_, axs = plt.subplots(ncols=3, figsize=(28, 8))\n",
    "i = 0\n",
    "\n",
    "for model in models_config:\n",
    "    cm = metrics.confusion_matrix(results[i][0], results[i][1])\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=testset.class_to_idx)\n",
    "    cm_display.plot(cmap=\"Blues\", ax=axs[i], text_kw={\"fontsize\": 14})\n",
    "\n",
    "    axs[i].set_title(f\"{model} confusion matrix\", y=1.02, fontsize=18)\n",
    "\n",
    "    axs[i].tick_params(axis=\"x\", rotation=45, labelsize=12)\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), ha=\"right\")\n",
    "\n",
    "    axs[i].tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "    axs[i].set_xlabel(\"Predicted label\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"True label\", fontsize=14)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.suptitle(\"Confusion matrix for all models\", fontsize=\"22\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate new_data once again, test hist eq vs no hist eq, run all experiments once again, add more metrics to rate model's performance, redefine datasetdivider, clean the main files' content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
