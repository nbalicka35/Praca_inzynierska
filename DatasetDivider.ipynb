{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddeed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7746b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./data/Training\"\n",
    "TEST_DIR = \"./data/Testing\"\n",
    "NEW_DIR = \"./new_data\"\n",
    "\n",
    "CLASSES = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_images():\n",
    "    all_imgs = []\n",
    "\n",
    "    for class_name in CLASSES:\n",
    "        train_class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "        if os.path.exists(train_class_dir):\n",
    "            for filename in os.listdir(train_class_dir):\n",
    "                if filename.lower().endswith(\".jpg\"):\n",
    "                    img_path = os.path.join(train_class_dir, filename)\n",
    "                    all_imgs.append((img_path, class_name))\n",
    "\n",
    "        test_class_dir = os.path.join(TEST_DIR, class_name)\n",
    "        if os.path.exists(test_class_dir):\n",
    "            for filename in os.listdir(test_class_dir):\n",
    "                if filename.lower().endswith(\".jpg\"):\n",
    "                    img_path = os.path.join(test_class_dir, filename)\n",
    "                    all_imgs.append((img_path, class_name))\n",
    "\n",
    "    return all_imgs\n",
    "\n",
    "\n",
    "def create_directory_structure():\n",
    "    for set in [\"Training\", \"Validation\", \"Testing\"]:\n",
    "        for class_name in CLASSES:\n",
    "            dir_path = os.path.join(NEW_DIR, set, class_name)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def split_and_copy(dataset):\n",
    "    paths = []\n",
    "    class_names = []\n",
    "\n",
    "    for path, _ in dataset:\n",
    "        paths.append(path)\n",
    "\n",
    "    for _, class_name in dataset:\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    train_paths, temp_paths, train_classes, temp_classes = train_test_split(\n",
    "        paths,\n",
    "        class_names,\n",
    "        train_size=TRAIN_SPLIT,\n",
    "        stratify=class_names,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    val_ratio_adjusted = VAL_SPLIT / (VAL_SPLIT + TEST_SPLIT)\n",
    "\n",
    "    val_paths, test_paths, val_classes, test_classes = train_test_split(\n",
    "        temp_paths,\n",
    "        temp_classes,\n",
    "        train_size=val_ratio_adjusted,\n",
    "        stratify=temp_classes,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    subsets = {\n",
    "        \"Training\": (train_paths, train_classes),\n",
    "        \"Validation\": (val_paths, val_classes),\n",
    "        \"Testing\": (test_paths, test_classes),\n",
    "    }\n",
    "\n",
    "    for subset, (s_path, s_class) in subsets.items():\n",
    "        for current_path, current_class in zip(s_path, s_class):\n",
    "            filename = os.path.basename(current_path)\n",
    "            dst = os.path.join(NEW_DIR, subset, current_class, filename)\n",
    "            if os.path.exists(dst):\n",
    "                dst = os.path.join(NEW_DIR, subset, current_class, f\"dup_{filename}\")\n",
    "\n",
    "            shutil.copy(current_path, dst)\n",
    "\n",
    "    return {\n",
    "        \"train\": (train_paths, train_classes),\n",
    "        \"val\": (val_paths, val_classes),\n",
    "        \"test\": (test_paths, test_classes),\n",
    "    }\n",
    "\n",
    "\n",
    "def print_statistics(dataset):\n",
    "    print(\"STATS FOR DATASET AFTER RANDOM DIVISION\")\n",
    "\n",
    "    for subset, (s_path, s_class) in dataset.items():\n",
    "        print(f\"{subset.upper()}: {len(s_path)} images total\")\n",
    "        counts = Counter(s_class)\n",
    "        for class_name in CLASSES:\n",
    "            count = counts.get(class_name, 0)\n",
    "            percentage = count / len(s_path) * 100\n",
    "\n",
    "            print(f\"\\t{class_name}: {count} ({percentage:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
